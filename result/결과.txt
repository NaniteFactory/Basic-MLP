6만 개 트레이닝 데이터셋을 학습시킨 결과입니다.

에러율 그래프는 이미지 파일로 첨부되어 있습니다.
epoch 12000회 수행에서 마지막 10번 정도의 에러율은 다음과 같습니다.

11990  MSError=0.024313, MSTestError=0.064779, |G|=1.825377
11991  MSError=0.004340, MSTestError=0.122883, |G|=0.510428
11992  MSError=0.022453, MSTestError=0.198184, |G|=3.999806
11993  MSError=0.004393, MSTestError=0.146741, |G|=0.506392
11994  MSError=0.000229, MSTestError=0.097384, |G|=0.030729
11995  MSError=0.001682, MSTestError=0.194455, |G|=0.383215
11996  MSError=0.135703, MSTestError=0.131164, |G|=4.361446
11997  MSError=0.061483, MSTestError=0.071381, |G|=2.701560
11998  MSError=0.081866, MSTestError=0.165717, |G|=4.485498
11999  MSError=0.019131, MSTestError=0.161126, |G|=2.044504
12000  MSError=0.011885, MSTestError=0.112295, |G|=0.806653

그래프를 보면 에러가 점차 줄어드는 것이 보이기는 하는데 떨림이 심합니다.
학습율이나 은닉층 노드의 수나 반복 횟수 등등을 바꿔 보면 결과로 출력되는 그래프 모양이 조금씩 달라지는 것은 보입니다.
여기에서 어떻게 하면 더 좋은 결과를 낼 수 있게 개선할 수 있을지에 대해서도 궁금하지만 일단은 처음 몇 번의 학습에서만 에러율이 크게 줄고 그 뒤로는 어느 수준 이하로 잘 내려가지 않는 것 같습니다.
